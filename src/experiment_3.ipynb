{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G-Mixup can improve the performance of graph neural networks on various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import os.path as osp\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from gmixup import prepare_dataset_onehot_y\n",
    "from utils import stat_graph\n",
    "import numpy as np\n",
    "from graphon_estimator import largest_gap\n",
    "from utils import split_class_graphs, align_graphs\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gmixup import prepare_dataset_x\n",
    "from utils import two_graphons_mixup\n",
    "from models import GIN, GCN, DiffPoolNet, TopKNet, MinCutPoolNet\n",
    "from gmixup import mixup_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'\n",
    "dataset_names = ['IMDB-MULTI', 'IMDB-BINARY', 'REDDIT-BINARY', 'REDDIT-MULTI-5K', 'REDDIT-MULTI-12K']\n",
    "models = ['GCN', 'GIN', 'MinCutPool', 'DiffPool', 'TopKPool']\n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "num_hidden = 64\n",
    "seeds = [1314, 311098, 271296, 180562, 280466, 50832, 280433, 21022, 0, 546464]\n",
    "no_test_runs = 10\n",
    "lam_range = [0.1, 0.2]\n",
    "aug_ratio = 0.2\n",
    "aug_num = 10\n",
    "augmentations = ['G-Mixup', 'Vanilla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    graph_all = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in train_loader:\n",
    "        # print( \"data.y\", data.y )\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        y = data.y.view(-1, num_classes)\n",
    "        #print(y.size())\n",
    "        #print(output.size())\n",
    "        loss = mixup_cross_entropy_loss(output, y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        graph_all += data.num_graphs\n",
    "        optimizer.step()\n",
    "        y = y.max(dim=1)[1]\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        total += data.num_graphs\n",
    "\n",
    "    loss = loss_all / graph_all\n",
    "    acc = correct / total\n",
    "    return model, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        y = data.y.view(-1, num_classes)\n",
    "        loss += mixup_cross_entropy_loss(output, y).item() * data.num_graphs\n",
    "        y = y.max(dim=1)[1]\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        total += data.num_graphs\n",
    "    acc = correct / total\n",
    "    loss = loss / total\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg num nodes of training graphs: 13.243809523809524\n",
      "Avg num edges of training graphs: 68.67238095238095\n",
      "Avg density of training graphs: 0.39152207454671556\n",
      "Median num edges of training graphs: 62.0\n",
      "Median density of training graphs: 0.62\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 1314, Aug: G-Mixup, Best epoch: 39, Test acc: 0.49, Test loss: 0.9553449503580729, Val acc: 0.5266666666666666, Val loss: 0.9595999280611675\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 1314, Aug: Vanilla, Best epoch: 23, Test acc: 0.515686274509804, Test loss: 0.9504871889656665, Val acc: 0.5666666666666667, Val loss: 0.989758103688558\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 311098, Aug: G-Mixup, Best epoch: 192, Test acc: 0.5058823529411764, Test loss: 1.0270820986990836, Val acc: 0.58, Val loss: 0.906507519086202\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 311098, Aug: Vanilla, Best epoch: 18, Test acc: 0.5305555555555556, Test loss: 0.9680224193467034, Val acc: 0.5533333333333333, Val loss: 0.9671762386957804\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 271296, Aug: G-Mixup, Best epoch: 19, Test acc: 0.5375, Test loss: 0.9909527778625489, Val acc: 0.6133333333333333, Val loss: 0.9548812834421794\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 271296, Aug: Vanilla, Best epoch: 131, Test acc: 0.5666666666666667, Test loss: 1.0319452387030406, Val acc: 0.5933333333333334, Val loss: 0.9574241026242574\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 180562, Aug: G-Mixup, Best epoch: 65, Test acc: 0.5516129032258065, Test loss: 1.013228907636417, Val acc: 0.68, Val loss: 0.8623796780904134\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 180562, Aug: Vanilla, Best epoch: 29, Test acc: 0.6008771929824561, Test loss: 0.9610198857491477, Val acc: 0.6466666666666666, Val loss: 0.9206736318270365\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 280466, Aug: G-Mixup, Best epoch: 57, Test acc: 0.5561403508771929, Test loss: 1.0351437154569123, Val acc: 0.6266666666666667, Val loss: 0.985074876944224\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 280466, Aug: Vanilla, Best epoch: 195, Test acc: 0.5940740740740741, Test loss: 1.0376474583590471, Val acc: 0.6333333333333333, Val loss: 0.975557557741801\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 50832, Aug: G-Mixup, Best epoch: 62, Test acc: 0.5874074074074074, Test loss: 1.041990374105948, Val acc: 0.6466666666666666, Val loss: 0.9345619996388753\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 50832, Aug: Vanilla, Best epoch: 163, Test acc: 0.5608974358974359, Test loss: 1.114855104837662, Val acc: 0.6533333333333333, Val loss: 1.3098086245854696\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 280433, Aug: G-Mixup, Best epoch: 59, Test acc: 0.6012820512820513, Test loss: 1.023689047495524, Val acc: 0.6533333333333333, Val loss: 0.9902672529220581\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 280433, Aug: Vanilla, Best epoch: 86, Test acc: 0.5514124293785311, Test loss: 1.243375263375751, Val acc: 0.6466666666666666, Val loss: 1.270228714942932\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 21022, Aug: G-Mixup, Best epoch: 48, Test acc: 0.6016949152542372, Test loss: 1.005022733965836, Val acc: 0.6066666666666667, Val loss: 0.9722299798329671\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 21022, Aug: Vanilla, Best epoch: 72, Test acc: 0.6156565656565657, Test loss: 1.0577783509938403, Val acc: 0.6133333333333333, Val loss: 1.0655988597869872\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 0, Aug: G-Mixup, Best epoch: 42, Test acc: 0.6065656565656565, Test loss: 1.0142427555238358, Val acc: 0.6866666666666666, Val loss: 0.9320451362927755\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 0, Aug: Vanilla, Best epoch: 11, Test acc: 0.6182648401826484, Test loss: 1.1495731704311283, Val acc: 0.6933333333333334, Val loss: 0.9312302939097087\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 546464, Aug: G-Mixup, Best epoch: 45, Test acc: 0.6164383561643836, Test loss: 1.261853364559069, Val acc: 0.6866666666666666, Val loss: 1.0345170291264851\n",
      "Dataset: IMDB-MULTI, Model: GCN, Seed: 546464, Aug: Vanilla, Best epoch: 92, Test acc: 0.59375, Test loss: 1.601164584159851, Val acc: 0.6666666666666666, Val loss: 1.3189738631248473\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 1314, Aug: G-Mixup, Best epoch: 7, Test acc: 0.61, Test loss: 0.9558522415161133, Val acc: 0.6533333333333333, Val loss: 0.943631820678711\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 1314, Aug: Vanilla, Best epoch: 7, Test acc: 0.6183908045977011, Test loss: 1.0149813797738818, Val acc: 0.6533333333333333, Val loss: 0.9584005626042684\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 311098, Aug: G-Mixup, Best epoch: 48, Test acc: 0.639080459770115, Test loss: 0.949815280364391, Val acc: 0.6933333333333334, Val loss: 0.9130771605173746\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 311098, Aug: Vanilla, Best epoch: 168, Test acc: 0.6078014184397164, Test loss: 0.9888064211987434, Val acc: 0.6933333333333334, Val loss: 0.922752070426941\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 271296, Aug: G-Mixup, Best epoch: 169, Test acc: 0.5971631205673759, Test loss: 0.9742057410537773, Val acc: 0.6266666666666667, Val loss: 0.9695710070927938\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 271296, Aug: Vanilla, Best epoch: 284, Test acc: 0.6125412541254125, Test loss: 0.9858990826622488, Val acc: 0.6733333333333333, Val loss: 0.9804354556401571\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 180562, Aug: G-Mixup, Best epoch: 215, Test acc: 0.6366336633663366, Test loss: 0.9738205262536657, Val acc: 0.68, Val loss: 0.9119833509127299\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 180562, Aug: Vanilla, Best epoch: 223, Test acc: 0.6246913580246913, Test loss: 1.1956723888715108, Val acc: 0.64, Val loss: 0.9813688532511393\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 280466, Aug: G-Mixup, Best epoch: 154, Test acc: 0.6308641975308642, Test loss: 0.9651361493416775, Val acc: 0.6, Val loss: 1.0148293161392212\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 280466, Aug: Vanilla, Best epoch: 152, Test acc: 0.6382608695652174, Test loss: 0.9959747305469236, Val acc: 0.6933333333333334, Val loss: 0.9799676815668742\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 50832, Aug: G-Mixup, Best epoch: 23, Test acc: 0.6371014492753623, Test loss: 0.9650267456925433, Val acc: 0.6266666666666667, Val loss: 0.9710898033777873\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 50832, Aug: Vanilla, Best epoch: 51, Test acc: 0.6256830601092896, Test loss: 1.079086331005305, Val acc: 0.6666666666666666, Val loss: 0.9564063556989034\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 280433, Aug: G-Mixup, Best epoch: 117, Test acc: 0.6177595628415301, Test loss: 0.976199507061901, Val acc: 0.6333333333333333, Val loss: 1.0022215048472087\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 280433, Aug: Vanilla, Best epoch: 22, Test acc: 0.630749354005168, Test loss: 0.9621031407854046, Val acc: 0.62, Val loss: 0.9886023489634196\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 21022, Aug: G-Mixup, Best epoch: 17, Test acc: 0.6387596899224807, Test loss: 0.987652168625085, Val acc: 0.66, Val loss: 0.9746165506045024\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 21022, Aug: Vanilla, Best epoch: 166, Test acc: 0.6267156862745098, Test loss: 0.979184068885504, Val acc: 0.7133333333333334, Val loss: 0.9319416093826294\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 0, Aug: G-Mixup, Best epoch: 9, Test acc: 0.6340686274509804, Test loss: 1.0492161956487918, Val acc: 0.6933333333333334, Val loss: 0.9643384806315104\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 0, Aug: Vanilla, Best epoch: 178, Test acc: 0.6296037296037296, Test loss: 0.9664723949554639, Val acc: 0.7466666666666667, Val loss: 0.8999738613764445\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 546464, Aug: G-Mixup, Best epoch: 118, Test acc: 0.6396270396270396, Test loss: 0.9612282134714104, Val acc: 0.7266666666666667, Val loss: 0.9120505309104919\n",
      "Dataset: IMDB-MULTI, Model: GIN, Seed: 546464, Aug: Vanilla, Best epoch: 9, Test acc: 0.6535555555555556, Test loss: 0.9722731481658088, Val acc: 0.72, Val loss: 0.927906752427419\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 1314, Aug: G-Mixup, Best epoch: 15, Test acc: 0.6597777777777778, Test loss: 0.9777054912779066, Val acc: 0.7066666666666667, Val loss: 0.9273243220647176\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 1314, Aug: Vanilla, Best epoch: 12, Test acc: 0.6602972399150743, Test loss: 0.9527013017113801, Val acc: 0.6866666666666666, Val loss: 0.9314672676722209\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 311098, Aug: G-Mixup, Best epoch: 45, Test acc: 0.6543524416135881, Test loss: 1.1531866353535096, Val acc: 0.6266666666666667, Val loss: 1.0006228065490723\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 311098, Aug: Vanilla, Best epoch: 49, Test acc: 0.6532520325203252, Test loss: 1.0119364579518637, Val acc: 0.7333333333333333, Val loss: 0.9681792322794597\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 271296, Aug: G-Mixup, Best epoch: 8, Test acc: 0.6589430894308943, Test loss: 0.9596371844532045, Val acc: 0.6866666666666666, Val loss: 0.9568535423278809\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 271296, Aug: Vanilla, Best epoch: 1, Test acc: 0.624561403508772, Test loss: 0.9818278120972259, Val acc: 0.7066666666666667, Val loss: 0.9390206209818522\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 180562, Aug: G-Mixup, Best epoch: 29, Test acc: 0.6469785575048733, Test loss: 0.9978078072995935, Val acc: 0.6866666666666666, Val loss: 1.0238664452234905\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 180562, Aug: Vanilla, Best epoch: 99, Test acc: 0.6365168539325843, Test loss: 1.0175418194760097, Val acc: 0.7133333333333334, Val loss: 0.9494199355443319\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 280466, Aug: G-Mixup, Best epoch: 50, Test acc: 0.6554307116104869, Test loss: 0.9709463212820475, Val acc: 0.72, Val loss: 0.9282984574635823\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 280466, Aug: Vanilla, Best epoch: 36, Test acc: 0.6499099099099099, Test loss: 0.99371994516871, Val acc: 0.58, Val loss: 1.0606960821151734\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 50832, Aug: G-Mixup, Best epoch: 45, Test acc: 0.6396396396396397, Test loss: 1.0234174230506827, Val acc: 0.6333333333333333, Val loss: 0.9922211043039958\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 50832, Aug: Vanilla, Best epoch: 160, Test acc: 0.5932291666666667, Test loss: 1.1667016983032226, Val acc: 0.62, Val loss: 1.194578563372294\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 280433, Aug: G-Mixup, Best epoch: 8, Test acc: 0.6305555555555555, Test loss: 0.9776331861813863, Val acc: 0.72, Val loss: 0.9239690415064494\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 280433, Aug: Vanilla, Best epoch: 179, Test acc: 0.6195979899497488, Test loss: 1.0663681199203185, Val acc: 0.6733333333333333, Val loss: 1.1177631815274556\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 21022, Aug: G-Mixup, Best epoch: 8, Test acc: 0.6480737018425461, Test loss: 0.9534275057727168, Val acc: 0.68, Val loss: 0.9417600138982137\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 21022, Aug: Vanilla, Best epoch: 37, Test acc: 0.6325242718446602, Test loss: 1.088834442521376, Val acc: 0.6666666666666666, Val loss: 1.2163728149731954\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 0, Aug: G-Mixup, Best epoch: 10, Test acc: 0.6496763754045307, Test loss: 0.9631476207844262, Val acc: 0.74, Val loss: 0.9164954956372579\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 0, Aug: Vanilla, Best epoch: 21, Test acc: 0.6535211267605634, Test loss: 0.9584004410369109, Val acc: 0.7, Val loss: 0.9827940861384074\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 546464, Aug: G-Mixup, Best epoch: 26, Test acc: 0.655868544600939, Test loss: 0.9866366914926746, Val acc: 0.72, Val loss: 0.9350473308563232\n",
      "Dataset: IMDB-MULTI, Model: MinCutPool, Seed: 546464, Aug: Vanilla, Best epoch: 6, Test acc: 0.6493939393939394, Test loss: 0.9890467155340946, Val acc: 0.72, Val loss: 0.9535731808344523\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 1314, Aug: G-Mixup, Best epoch: 74, Test acc: 0.6448484848484849, Test loss: 1.0614891168565461, Val acc: 0.7, Val loss: 0.951852445602417\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 1314, Aug: Vanilla, Best epoch: 206, Test acc: 0.6375917767988253, Test loss: 1.0804392105682306, Val acc: 0.6866666666666666, Val loss: 1.1392315689722696\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 311098, Aug: G-Mixup, Best epoch: 87, Test acc: 0.6430249632892805, Test loss: 1.0034679492489706, Val acc: 0.72, Val loss: 0.9088647397359212\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 311098, Aug: Vanilla, Best epoch: 45, Test acc: 0.638034188034188, Test loss: 1.0164837500308654, Val acc: 0.66, Val loss: 0.9992984501520793\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 271296, Aug: G-Mixup, Best epoch: 30, Test acc: 0.6452991452991453, Test loss: 0.9693327173548206, Val acc: 0.68, Val loss: 0.9399349117279052\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 271296, Aug: Vanilla, Best epoch: 7, Test acc: 0.6402489626556016, Test loss: 0.9878882417375451, Val acc: 0.6266666666666667, Val loss: 0.9965249490737915\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 180562, Aug: G-Mixup, Best epoch: 15, Test acc: 0.6531120331950208, Test loss: 0.969136290860209, Val acc: 0.7133333333333334, Val loss: 0.9474239333470662\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 180562, Aug: Vanilla, Best epoch: 124, Test acc: 0.6463709677419355, Test loss: 1.0397972181279171, Val acc: 0.74, Val loss: 0.8956832162539164\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 280466, Aug: G-Mixup, Best epoch: 36, Test acc: 0.6508064516129032, Test loss: 0.9876046865217147, Val acc: 0.7466666666666667, Val loss: 0.9016455904642741\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 280466, Aug: Vanilla, Best epoch: 71, Test acc: 0.6601307189542484, Test loss: 1.0438337542652305, Val acc: 0.6466666666666666, Val loss: 1.0301766443252562\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 50832, Aug: G-Mixup, Best epoch: 37, Test acc: 0.6580392156862745, Test loss: 0.9989341661041858, Val acc: 0.6866666666666666, Val loss: 0.9569306230545044\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 50832, Aug: Vanilla, Best epoch: 131, Test acc: 0.6526717557251909, Test loss: 1.0534895276901983, Val acc: 0.6733333333333333, Val loss: 1.0187389787038168\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 280433, Aug: G-Mixup, Best epoch: 7, Test acc: 0.6483460559796438, Test loss: 0.9733698360792553, Val acc: 0.7133333333333334, Val loss: 0.9539711006482442\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 280433, Aug: Vanilla, Best epoch: 8, Test acc: 0.6503097893432466, Test loss: 0.9727026910143713, Val acc: 0.7066666666666667, Val loss: 0.9730450963973999\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 21022, Aug: G-Mixup, Best epoch: 19, Test acc: 0.6650557620817844, Test loss: 0.9830241369639778, Val acc: 0.6466666666666666, Val loss: 1.1410438791910806\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 21022, Aug: Vanilla, Best epoch: 31, Test acc: 0.6596618357487922, Test loss: 0.9743181349574656, Val acc: 0.7866666666666666, Val loss: 0.8722195251782735\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 0, Aug: G-Mixup, Best epoch: 6, Test acc: 0.6589371980676328, Test loss: 0.9766020148848565, Val acc: 0.6933333333333334, Val loss: 0.9459796984990437\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 0, Aug: Vanilla, Best epoch: 46, Test acc: 0.662190812720848, Test loss: 0.9927518076273241, Val acc: 0.7, Val loss: 0.9416014258066813\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 546464, Aug: G-Mixup, Best epoch: 75, Test acc: 0.6587750294464075, Test loss: 1.0394975719519302, Val acc: 0.68, Val loss: 1.0203325668970744\n",
      "Dataset: IMDB-MULTI, Model: DiffPool, Seed: 546464, Aug: Vanilla, Best epoch: 12, Test acc: 0.662183908045977, Test loss: 0.9726736892228839, Val acc: 0.6533333333333333, Val loss: 1.0055807034174602\n",
      "Dataset: IMDB-MULTI, Model: TopKPool, Seed: 1314, Aug: G-Mixup, Best epoch: 98, Test acc: 0.6502298850574713, Test loss: 1.011554871948286, Val acc: 0.7666666666666667, Val loss: 0.9372877645492553\n",
      "Dataset: IMDB-MULTI, Model: TopKPool, Seed: 1314, Aug: Vanilla, Best epoch: 73, Test acc: 0.661391694725028, Test loss: 1.144074183441573, Val acc: 0.6466666666666666, Val loss: 1.0240350691477458\n",
      "Dataset: IMDB-MULTI, Model: TopKPool, Seed: 311098, Aug: G-Mixup, Best epoch: 215, Test acc: 0.6640852974186308, Test loss: 0.9738944856406061, Val acc: 0.6933333333333334, Val loss: 0.9612712375322978\n",
      "Dataset: IMDB-MULTI, Model: TopKPool, Seed: 311098, Aug: Vanilla, Best epoch: 70, Test acc: 0.6646929824561404, Test loss: 0.9729726251802946, Val acc: 0.6866666666666666, Val loss: 0.9901432100931803\n",
      "Dataset: IMDB-MULTI, Model: TopKPool, Seed: 271296, Aug: G-Mixup, Best epoch: 96, Test acc: 0.6657894736842105, Test loss: 2.152455971115514, Val acc: 0.7466666666666667, Val loss: 0.9207621264457703\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    path = osp.join(data_path, dataset_name)\n",
    "    dataset = TUDataset(path, name=dataset_name)\n",
    "    dataset = list(dataset)\n",
    "    for graph in dataset:\n",
    "        graph.y = graph.y.view(-1)\n",
    "\n",
    "    dataset = prepare_dataset_onehot_y(dataset)\n",
    "    train_nums = int(len(dataset) * 0.7)\n",
    "    train_val_nums = int(len(dataset) * 0.8)\n",
    "\n",
    "    avg_num_nodes, avg_num_edges, avg_density, median_num_nodes, median_num_edges, median_density = stat_graph(dataset[:train_nums])\n",
    "    graphon_size = int(median_num_nodes)\n",
    "    print(f\"Avg num nodes of training graphs: {avg_num_nodes}\")\n",
    "    print(f\"Avg num edges of training graphs: {avg_num_edges}\")\n",
    "    print(f\"Avg density of training graphs: {avg_density}\")\n",
    "    print(f\"Median num edges of training graphs: {median_num_edges}\")\n",
    "    print(f\"Median density of training graphs: {median_density}\")\n",
    "    for model_name in models:\n",
    "        for seed in seeds:\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            random.shuffle(dataset)\n",
    "            for aug in augmentations:\n",
    "                random.shuffle(dataset)\n",
    "                if aug == 'G-Mixup':\n",
    "                    class_graphs = split_class_graphs(dataset[:train_nums])\n",
    "                    graphons = []\n",
    "                    for label, graphs in class_graphs:\n",
    "                        align_graphs_list, normalized_node_degrees, max_num, min_num = align_graphs(\n",
    "                            graphs, padding=True, N=graphon_size)\n",
    "                        graphon = largest_gap(align_graphs_list, k=graphon_size)\n",
    "                        graphons.append((label, graphon))\n",
    "\n",
    "                    num_sample = int(train_nums * aug_ratio / aug_num)\n",
    "                    lam_list = np.random.uniform(low=lam_range[0], high=lam_range[1], size=(aug_num,))\n",
    "\n",
    "                    random.seed(seed)\n",
    "                    new_graph = []\n",
    "                    for lam in lam_list:\n",
    "                        two_graphons = random.sample(graphons, 2)\n",
    "                        new_graph += two_graphons_mixup(two_graphons, la=lam, num_sample=num_sample)\n",
    "\n",
    "                    new_dataset = new_graph + dataset\n",
    "                    new_train_nums = train_nums + len(new_graph)\n",
    "                    new_train_val_nums = train_val_nums + len(new_graph)\n",
    "                else:\n",
    "                    new_dataset = dataset\n",
    "                    new_train_nums = train_nums\n",
    "                    new_train_val_nums = train_val_nums\n",
    "\n",
    "                new_dataset = prepare_dataset_x(new_dataset)\n",
    "\n",
    "                num_features = new_dataset[0].x.shape[1]\n",
    "                num_classes = new_dataset[0].y.shape[0]\n",
    "\n",
    "                # avg_num_nodes, avg_num_edges, avg_density, median_num_nodes, median_num_edges, median_density = stat_graph(new_dataset[:new_train_nums])\n",
    "                # print(f\"Avg num nodes of new training graphs: {avg_num_nodes}\")\n",
    "                # print(f\"Avg num edges of new training graphs: {avg_num_edges}\")\n",
    "                # print(f\"Avg density of new training graphs: {avg_density}\")\n",
    "                # print(f\"Median num edges of new training graphs: {median_num_edges}\")\n",
    "                # print(f\"Median density of new training graphs: {median_density}\")\n",
    "                train_dataset = new_dataset[:new_train_nums]\n",
    "                random.shuffle(train_dataset)\n",
    "                val_dataset = new_dataset[new_train_nums:new_train_val_nums]\n",
    "                test_dataset = new_dataset[new_train_val_nums:]\n",
    "\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "                if model_name == \"GIN\":\n",
    "                    model = GIN(num_features=num_features, num_classes=num_classes, num_hidden=num_hidden).to(device)\n",
    "                elif model_name == \"GCN\":\n",
    "                    model = GCN(in_channels=num_features, hidden_channels=num_hidden, out_channels=num_classes, num_layers=4).to(device)\n",
    "                elif model_name == \"TopKPool\":\n",
    "                    model = TopKNet(in_channels=num_features, hidden_channels=num_hidden, out_channels=num_classes).to(device)\n",
    "                elif model_name == \"DiffPool\":\n",
    "                    model = DiffPoolNet(in_channels=num_features, hidden_channels=num_hidden, out_channels=num_classes, max_nodes = median_num_nodes).to(device)\n",
    "                elif model_name == \"MinCutPool\":\n",
    "                    model = MinCutPoolNet(in_channels=num_features, hidden_channels=num_hidden, out_channels=num_classes, max_nodes = median_num_nodes).to(device)\n",
    "                else:\n",
    "                    model = None\n",
    "\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                scheduler = StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "                max_val_acc = 0\n",
    "                model_test_acc = 0\n",
    "                model_test_loss = 0\n",
    "                model_val_loss = 0\n",
    "                best_epoch = 0\n",
    "                train_losses = []\n",
    "                val_losses = []\n",
    "                test_losses = []\n",
    "                for epoch in range(1, epochs):\n",
    "                    model, train_loss, train_acc = train(model, train_loader)\n",
    "                    val_acc, val_loss = test(model, val_loader)\n",
    "                    test_acc, test_loss = test(model, test_loader)\n",
    "                    scheduler.step()\n",
    "                    train_losses.append(train_loss)\n",
    "                    val_losses.append(val_loss)\n",
    "                    test_losses.append(test_loss)\n",
    "                    if val_acc > max_val_acc:\n",
    "                        max_val_acc = val_acc\n",
    "                        model_test_loss = test_loss\n",
    "                        model_test_acc = test_acc\n",
    "                        model_val_loss = val_loss\n",
    "                        best_epoch = epoch\n",
    "                    #if epoch%20==0:\n",
    "                    #    print(\n",
    "                    #        'Epoch: {:03d}, Train Loss: {:.6f}, Val Loss: {:.6f}, Test Loss: {:.6f}, Train acc: {: .6f}, Val Acc: {: .6f}, Test Acc: {: .6f}'.format(\n",
    "                    #            epoch, train_loss, val_loss, test_loss, train_acc, val_acc, test_acc))\n",
    "\n",
    "                with open('train_log.txt', 'a') as f:\n",
    "                    f.write(f'Dataset: {dataset_name}, Model: {model_name}, Seed: {seed}, Aug: {aug}, Best epoch: {best_epoch}, Test acc: {model_test_acc}, Test loss: {model_test_loss}, Val acc: {max_val_acc}, Val loss: {model_val_loss}\\n')\n",
    "                if model_name == 'GCN':\n",
    "                    with open('../results/losses.txt', 'a') as f:\n",
    "                        f.write(f'{dataset_name}, {seed}, train, {train_losses}\\n{dataset_name}, {seed}, val, {val_losses}\\n{dataset_name}, {seed}, test, {test_losses}\\n')\n",
    "                print(f'Dataset: {dataset_name}, Model: {model_name}, Seed: {seed}, Aug: {aug}, Best epoch: {best_epoch}, Test acc: {model_test_acc}, Test loss: {model_test_loss}, Val acc: {max_val_acc}, Val loss: {model_val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
